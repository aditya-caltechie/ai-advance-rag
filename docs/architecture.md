# System Architecture - Advanced RAG Pipeline

This document provides a comprehensive overview of the entire RAG pipeline system architecture, including both implementations and the evaluation framework.

## ğŸ“ High-Level System Architecture

```mermaid
graph TB
    subgraph "Knowledge Base"
        KB[ğŸ“š Markdown Documents<br/>knowledge-base/]
    end
    
    subgraph "Implementation Choice"
        CHOICE{Choose Implementation}
        CHOICE -->|Basic| BASIC[implementation/]
        CHOICE -->|Advanced| ADV[pro_implementation/]
    end
    
    subgraph "Ingestion Pipeline"
        KB --> INGEST[Run ingest.py]
        BASIC --> INGEST
        ADV --> INGEST
        INGEST --> VDB[(Vector Database<br/>ChromaDB)]
    end
    
    subgraph "User Interface"
        USER[ğŸ‘¤ User] --> UI[Gradio Web App<br/>app.py]
    end
    
    subgraph "Query Pipeline"
        UI --> ANSWER[answer.py]
        VDB -.->|Retrieve| ANSWER
        ANSWER --> LLM[ğŸ¤– LLM Generation]
        LLM --> RESPONSE[Answer + Context]
        RESPONSE --> UI
    end
    
    subgraph "Evaluation Framework"
        EVAL[evaluator.py] --> EVAL_IMPL[evaluation/eval.py]
        EVAL_IMPL --> TEST[Test Cases<br/>evaluation/test.py]
        EVAL_IMPL --> ANSWER
        EVAL_IMPL --> METRICS[ğŸ“Š Metrics Dashboard]
    end
    
    style KB fill:#e3f2fd
    style VDB fill:#fff3e0
    style USER fill:#e8f5e9
    style METRICS fill:#f3e5f5
    style CHOICE fill:#fff9c4
```

---

## ğŸ”„ Complete System Flow

### End-to-End Journey

```mermaid
sequenceDiagram
    participant Admin as System Admin
    participant Docs as Knowledge Base
    participant Ingest as Ingestion
    participant VDB as Vector Database
    participant User as End User
    participant UI as Web Interface
    participant Query as Query Pipeline
    participant LLM as Language Model
    participant Eval as Evaluator
    
    Note over Admin,Ingest: Phase 1: Setup
    Admin->>Docs: Add/Update Documents
    Admin->>Ingest: Run ingest.py
    Ingest->>Docs: Load Documents
    Ingest->>Ingest: Chunk & Process
    Ingest->>VDB: Store Embeddings
    
    Note over User,LLM: Phase 2: User Interaction
    User->>UI: Ask Question
    UI->>Query: Forward Question
    Query->>VDB: Retrieve Context
    VDB-->>Query: Return Chunks
    Query->>LLM: Generate with Context
    LLM-->>Query: Return Answer
    Query-->>UI: Answer + Sources
    UI-->>User: Display Response
    
    Note over Admin,Eval: Phase 3: Evaluation
    Admin->>Eval: Run Evaluation
    Eval->>Query: Test Multiple Questions
    Query-->>Eval: Return Results
    Eval->>Eval: Calculate Metrics
    Eval-->>Admin: Display Dashboard
```

---

## ğŸ—ï¸ Detailed Component Architecture

### 1. Ingestion Pipeline Architecture

```mermaid
graph TB
    subgraph "Input Layer"
        FILES[ğŸ“„ Markdown Files<br/>knowledge-base/*/*.md]
    end
    
    subgraph "Processing Layer"
        LOAD[Document Loader<br/>DirectoryLoader]
        FILES --> LOAD
        
        LOAD --> ROUTE{Implementation?}
        
        ROUTE -->|Basic| SIMPLE[Simple Chunking<br/>RecursiveCharacterTextSplitter<br/>500 chars, 200 overlap]
        ROUTE -->|Advanced| SMART[LLM Chunking<br/>GPT-4.1 Semantic Split<br/>+ Headlines + Summaries]
        
        SIMPLE --> CHUNKS1[Plain Text Chunks]
        SMART --> CHUNKS2[Enhanced Chunks<br/>headline + summary + text]
    end
    
    subgraph "Embedding Layer"
        CHUNKS1 --> EMB[OpenAI Embeddings<br/>text-embedding-3-large<br/>3072 dimensions]
        CHUNKS2 --> EMB
        EMB --> VECTORS[Vector Representations]
    end
    
    subgraph "Storage Layer"
        VECTORS --> STORE{Storage Path}
        STORE -->|Basic| DB1[(vector_db/<br/>~180 vectors)]
        STORE -->|Advanced| DB2[(preprocessed_db/<br/>~245 vectors)]
    end
    
    style FILES fill:#e3f2fd
    style SIMPLE fill:#ffccbc
    style SMART fill:#c8e6c9
    style DB1 fill:#fff3e0
    style DB2 fill:#fff3e0
```

### 2. Query Pipeline Architecture

#### Basic RAG Query Flow

```mermaid
graph LR
    Q[â“ User Question] --> H[ğŸ“ History Concat]
    H --> E[ğŸ§® Embed Query]
    E --> S[ğŸ” Vector Search<br/>Similarity Top-10]
    S --> DB1[(vector_db)]
    DB1 -.->|Chunks| C[ğŸ“‹ Format Context]
    C --> P[ğŸ¯ Build Prompt<br/>System + Context + Question]
    P --> L[ğŸ¤– LLM Generate<br/>GPT-4.1-nano]
    L --> A[âœ… Answer]
    
    style Q fill:#e8f5e9
    style S fill:#fce4ec
    style L fill:#e1f5fe
    style A fill:#c8e6c9
```

#### Advanced RAG Query Flow

```mermaid
graph TB
    Q[â“ User Question] --> R[ğŸ”„ LLM Rewrite<br/>Extract key terms]
    
    R --> S1[ğŸ” Search #1<br/>Original Query<br/>Top-20]
    R --> S2[ğŸ” Search #2<br/>Rewritten Query<br/>Top-20]
    
    S1 --> DB[(preprocessed_db)]
    S2 --> DB
    
    DB -.->|Chunks| M[ğŸ”— Merge & Dedupe<br/>~30-40 unique chunks]
    
    M --> RK[ğŸ¯ LLM Rerank<br/>Semantic Relevance<br/>GPT-4.1-nano]
    
    RK --> T[ğŸ“Š Select Top-10<br/>Best Quality]
    
    T --> P[ğŸ¯ Build Prompt<br/>System + Context + Question]
    
    P --> L[ğŸ¤– LLM Generate<br/>With Enhanced Context]
    
    L --> A[âœ… Answer + Sources]
    
    style Q fill:#e8f5e9
    style R fill:#fff9c4
    style RK fill:#fff9c4
    style L fill:#fff9c4
    style A fill:#c8e6c9
    style M fill:#e1bee7
```

### 3. Evaluation Architecture

```mermaid
graph TB
    subgraph "Test Suite"
        TC[Test Cases<br/>evaluation/test.py<br/>Questions + Expected Results]
    end
    
    subgraph "Evaluation Engine"
        TC --> EVAL[evaluator.py<br/>Gradio Dashboard]
        EVAL --> CHOICE{Evaluation Type}
        
        CHOICE -->|Retrieval| RET[evaluate_all_retrieval]
        CHOICE -->|Answer| ANS[evaluate_all_answers]
        
        RET --> IMPL[Implementation<br/>ingest/answer modules]
        ANS --> IMPL
        
        IMPL --> VDB[(Vector DB)]
        VDB -.-> IMPL
    end
    
    subgraph "Metrics Calculation"
        RET --> MRR[MRR<br/>Mean Reciprocal Rank]
        RET --> NDCG[nDCG<br/>Normalized DCG]
        RET --> COV[Coverage<br/>Keyword Match %]
        
        ANS --> LLM_JUDGE[ğŸ¤– LLM as Judge<br/>GPT-4 Scoring]
        LLM_JUDGE --> ACC[Accuracy<br/>1-5 scale]
        LLM_JUDGE --> COMP[Completeness<br/>1-5 scale]
        LLM_JUDGE --> REL[Relevance<br/>1-5 scale]
    end
    
    subgraph "Visualization"
        MRR --> DASH[ğŸ“Š Dashboard<br/>Color-coded Metrics]
        NDCG --> DASH
        COV --> DASH
        ACC --> DASH
        COMP --> DASH
        REL --> DASH
        
        DASH --> CHART[ğŸ“ˆ Category Charts<br/>Bar Plots]
    end
    
    style TC fill:#e3f2fd
    style DASH fill:#f3e5f5
    style CHART fill:#c5cae9
    style LLM_JUDGE fill:#fff9c4
```

---

## ğŸ¨ User Interface Architecture

```mermaid
graph TB
    subgraph "Frontend - Gradio UI"
        USER[ğŸ‘¤ User Browser]
        
        USER --> CHAT[ğŸ’¬ Chatbot Panel<br/>Conversation History]
        USER --> INPUT[âŒ¨ï¸ Text Input<br/>Question Box]
        
        CHAT --> DISPLAY[Display Messages]
        INPUT --> SUBMIT[Submit Handler]
    end
    
    subgraph "Backend Logic"
        SUBMIT --> PROCESS[Process Message]
        PROCESS --> BACKEND[answer_question]
        
        BACKEND --> IMPL{Which Implementation?}
        IMPL -->|Basic| B_ANSWER[implementation/answer.py]
        IMPL -->|Advanced| A_ANSWER[pro_implementation/answer.py]
        
        B_ANSWER --> RESULT[Result Handler]
        A_ANSWER --> RESULT
    end
    
    subgraph "Response Display"
        RESULT --> UPD_CHAT[Update Chat<br/>Add Assistant Message]
        RESULT --> UPD_CTX[Update Context Panel<br/>Show Retrieved Docs]
        
        UPD_CHAT --> DISPLAY
        UPD_CTX --> CTX_PANEL[ğŸ“š Context Panel<br/>Source Documents]
    end
    
    style USER fill:#e8f5e9
    style CHAT fill:#e1f5fe
    style CTX_PANEL fill:#fff3e0
    style IMPL fill:#fff9c4
```

---

## ğŸ’¾ Database Architecture

### Vector Database Schema

```mermaid
graph TB
    subgraph "ChromaDB Structure"
        COL[Collection: 'docs']
        
        COL --> DOC[Documents<br/>Text content]
        COL --> EMB[Embeddings<br/>3072-dim vectors]
        COL --> META[Metadata<br/>source, type]
        COL --> ID[IDs<br/>Unique identifiers]
    end
    
    subgraph "Basic Implementation"
        DB1[(vector_db/)]
        DB1 --> C1[Collection: vector_db]
        C1 --> D1[~180 documents<br/>Plain text chunks]
    end
    
    subgraph "Advanced Implementation"
        DB2[(preprocessed_db/)]
        DB2 --> C2[Collection: docs]
        C2 --> D2[~245 documents<br/>Enhanced chunks<br/>headline + summary + text]
    end
    
    style COL fill:#fff3e0
    style DB1 fill:#ffccbc
    style DB2 fill:#c8e6c9
```

---

## ğŸ“ Summary

### System Characteristics

| Component | Basic RAG | Advanced RAG |
|-----------|-----------|--------------|
| **Ingestion** | Simple, fast | Complex, thorough |
| **Chunking** | Rule-based | LLM-powered |
| **Retrieval** | Single query | Dual query + rerank |
| **Latency** | 1-2s | 3-5s |
| **Cost/Query** | $0.001 | $0.01-0.02 |
| **Accuracy** | 75% | 92% |
| **Use Case** | Prototyping, simple docs | Production, complex docs |

### Architecture Principles

1. **Modularity**: Implementations are swappable
2. **Evaluation-Driven**: Built-in metrics and testing
3. **Progressive Enhancement**: Start basic, upgrade as needed
4. **Cost-Aware**: Clear trade-offs documented
5. **Production-Ready**: Both paths viable for deployment

---

## ğŸ”— Related Documentation

- [Basic RAG Architecture](basic_rag_architecture.md) - Detailed basic flow
- [Advanced RAG Architecture](advanced_rag_architecture.md) - Detailed advanced flow
- [Architecture Comparison](architecture_comparison.md) - Side-by-side comparison
- [Workflow Guide](workflow_guide.md) - How to use the system
- [Complete Journey](complete_journey.md) - User journey map

---

*Last Updated: 2026-02*
